{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Walkthrough 1: Running Local Large Language Models (LLMs)\n",
    "\n",
    "A key risks raised repeatedly within the challenge was that of Data Privacy when using an LLM. When we interact with an LLM we sometimes need to provide additional context which may include data that your company does not want to be sent over the internet to a 3rd party. While companies such as OpenAI (ChatGPT) and Microsoft (Bing Copilot) allow you to opt out from your data being used in training many companies prefer to remove the risk by using Open-Source LLMs locally.\n",
    "\n",
    "In recent years there has been a growth in Open Source LLMs (such as Llama 2 from Meta or BERT from Google) - they use similar architectures to ChatGPT and Bing Copilot and share similar approaches to training the models.  These allow companies, if they want, to run LLMs locally.\n",
    "\n",
    "Running an LLM locally does have some drawbacks:\n",
    "* Generally larger LLM models will perform better but will require greater compute (memory and CPU/GPU) to be performant.\n",
    "* The company needs to provide the infrastructure to host and run the model\n",
    "* As the models evolve, the companies need to manage the model upgrades\n",
    "\n",
    "However, running local LLMS models have a number of key benefits:\n",
    "* Enhanced Data Security and Privacy since no data is sent to 3rd parties\n",
    "* Cost saving and reduction in vendor lock in\n",
    "* Ability to customise the LLM for their purposes\n",
    "\n",
    "This walkthrough will show you 2 ways to do this:\n",
    "* Using LlamaFile\n",
    "* Using HuggingFace\n",
    "\n",
    "> NOTE: This is not an exhaustive guide to deploying LLMs locally, instead it is to show you what is possible \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "876b7e6d60c18e1a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Related Resources:\n",
    "\n",
    "| Link                                               | Description                                                                                                                                             |\n",
    "|----------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| https://www.datacamp.com/blog/top-open-source-llms | Introductory article on using Open Source LLMs                                                                                                          |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba0a317b03c1a965"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using LlamaFile\n",
    "If you like the conversational style of tools such as Bing Copilot or ChatGPT you can host your own LLM in your desktop or a local server using an interesting project from Mozilla (https://www.mozilla.org/) called **LlamaFile**.\n",
    "\n",
    "The **LlmaFile** project aims to package up Open-Source Large Language Models into an executable that can be run as local webserver with a simple Chat Inferface and an API for you to query.\n",
    "\n",
    "The project can be found at https://github.com/Mozilla-Ocho/llamafile\n",
    "\n",
    "The project's ReadMe file contains instructions on how you can download an image and get it to run on your local machine.\n",
    "\n",
    "There are a few points to remember:\n",
    "* The LLM models you can access are limited to Open-Source models - you won't find models such as GTP3.5, GPT4 available in LlamaFile as these are closed source.\n",
    "* Large Language Models take a large amount of memory, so it's unlikely that you will be able to run a model the size of GPT on your desktop and so performance may not be as good. \n",
    "* The text generation may be slow depending on the power of your local machine.\n",
    "\n",
    "> IMPORTANT: You will need to be able to run arbitrary executables on your machine. \n",
    "> Some company IT Security may prohibit this so please check before downloading and attempting to run the LlamaFile on company machines. \n",
    "\n",
    "For today's task I would suggest:\n",
    "1. Navigate to the LlamaFile Homepage (https://github.com/Mozilla-Ocho/llamafile)\n",
    "2. Pick one of the smaller models liked on LlamaFile.\n",
    "3. Download the file and follow the instructions to run the LlamaFile\n",
    "4. Explore some conversations with your personal LLM.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "251905c45ada98b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Questions for Reflection\n",
    "\n",
    "You have now downloaded and successfully run your own local LLM - ok, so it was only a small one but the purpose here was to show you that running an LLM locally is possible.\n",
    "\n",
    "Before closing this workbook, reflect on the following questions:\n",
    "\n",
    "1. In what ways did running an LLM locally differ from using a service such as Chat-GPT? How might any limitations be overcome?\n",
    "3. What use cases might your team have for deploying a local LLM?\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6d86bf296f70c51"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f9d3ebbe8c6c4b1d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
